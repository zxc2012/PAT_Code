# CS61C Lecture5 --Parallelism

## Basics

![](https://raw.githubusercontent.com/zxc2012/image/main/20220428200039.png)

### Amdahl’s Law

![](https://raw.githubusercontent.com/zxc2012/image/main/20220428200528.png)

Speedup =$\frac{t_{prev}}{t_{cur}} = \frac{1}{(1-F)+F/S}$

F = Fraction of execution time speed up

S = Scale of improvement

## SIMD

### SIMD Architecture

![](https://raw.githubusercontent.com/zxc2012/image/main/20220505211439.png)

X86 Intrinsics AVX Data Type

![](https://raw.githubusercontent.com/zxc2012/image/main/20220505211808.png)

Intrinsics AVX Code nomenclature [ˈnomənˌkletʃɚ]`name call`

![](https://raw.githubusercontent.com/zxc2012/image/main/20220505212039.png)

![](https://raw.githubusercontent.com/zxc2012/image/main/20220505212550.png)

### Example

#### Matrix Multiply

![](https://raw.githubusercontent.com/zxc2012/image/main/20220505213302.png)

![](https://raw.githubusercontent.com/zxc2012/image/main/20220505214347.png)

```cpp
#include <stdio.h>
// header file for SSE4.2 compiler intrinsics
#include <nmmintrin.h>
// NOTE: vector registers will be represented in
comments as v1 = [ a | b]
// where v1 is a variable of type __m128d and
a,b are doubles
int main(void) {
    // allocate A,B,C aligned on 16-byte boundaries
    double A[4] __attribute__ ((aligned (16)));
    double B[4] __attribute__ ((aligned (16)));
    double C[4] __attribute__ ((aligned (16)));
    int lda = 2;
    int i = 0;
    // declare a couple 128-bit vector variables
    __m128d c1,c2,a,b1,b2;
    A[0] = 1.0; A[1] = 0.0; A[2] = 0.0; A[3] = 1.0;
    B[0] = 1.0; B[1] = 2.0; B[2] = 3.0; B[3] = 4.0;
    C[0] = 0.0; C[1] = 0.0; C[2] = 0.0; C[3] = 0.0;

    c1 = _mm_load_pd(C+0*lda);
    c2 = _mm_load_pd(C+1*lda);
    for (i = 0; i < 2; i++) {

        a = _mm_load_pd(A+i*lda);

        b1 = _mm_load1_pd(B+i+0*lda);
        b2 = _mm_load1_pd(B+i+1*lda);

        c1 = _mm_add_pd(c1,_mm_mul_pd(a,b1));
        c2 = _mm_add_pd(c2,_mm_mul_pd(a,b2));
    }
    // store c1,c2 back into C for completion
    _mm_store_pd(C+0*lda,c1);
    _mm_store_pd(C+1*lda,c2);

    printf("%g,%g\n%g,%g\n",C[0],C[2],C[1],C[3]);
    return 0;
}
```

#### Loop Unrolling

Loop Unrolling in C
```cpp
for(i=0; i<1000; i++)
    x[i] = x[i] + s;
//Unrolling
for(i=0; i<1000; i=i+4) {
    x[i] = x[i] + s;
    x[i+1] = x[i+1] + s;
    x[i+2] = x[i+2] + s;
    x[i+3] = x[i+3] + s;
}
```

RISCV
```armasm
Loop:
lw t0, 0(s0)
addu t0,t0,s1 # add b to array element
sw t0,0(s0) # store result
addi s0,s0,4 # move to next element
bne s0,s2,Loop # repeat Loop if not done

Unrolling Loop:
lw t0,0(s0)
lw t1,4(s0)
lw t2,8(s0)
lw t3,12(s0) # 4 wide SIMD Load
add t0,t0,s1
add t1,t1,s1
add t2,t2,s1
add t3,t3,s1 # 4 wide SIMD Add
sw t0,0(s0)
sw t1,4(s0)
sw t2,8(s0)
sw t3,12(s0) # 4 wide SIMD Store
addi s0,s0,16
bne s0,s2,Loop
```

## MIMD

### OpenMP
#### Synchronization

Reduction: specifies that 1 or more variables that are private to each thread are subject of *reduction* operation at **end** of parallel region

```cpp
double compute_sum(double *a, int a_len) {
    double sum = 0.0;
    #pragma omp parallel for reduction(+ : sum)
    for (int i = 0; i < a_len; i++) {
        sum += a[i];
    }
    return sum;
}
```

#### Pitfalls

- Data dependencies
    ```cpp
    a[0] = 1;
    for(i=1; i<5000; i++)
        a[i] = i + a[i-1];
    ```
- Sharing Issues
    ```cpp
    // Problem
    #pragma omp parallel for //Each thread accesses different elements of a, b,and c, but the same temp
    for(i=0; i<n; i++){
        temp = 2.0*a[i];
        a[i] = temp;
        b[i] = c[i]/temp;
    } 
    // Correct
    #pragma omp parallel for private(temp)
    for(i=0; i<n; i++){
        temp = 2.0*a[i];
        a[i] = temp;
        b[i] = c[i]/temp;
    }
    ```
- Updating Shared Variables Simultaneously 

    This can be done by surrounding the summation by a critical/atomic section or reduction clause

- Parallel Overhead

    Parallelize over the largest loop that you can (even though it will involve more work to declare all of the private variables and eliminate dependencies)

## Cache Coherence

### MSI

||Valid Bit| Dirty Bit| Shared Bit|
|-|-|-|-|
|Modified| 1 |1| 0|
|Shared |1 |0 |X |
|Invalid| 0 |X |X |

- Modified: up-to-date, changed (dirty), OK to write
    - no other cache has a copy
- Shared: up-to-date data, not allowed to write
    - **other caches may have a copy**
- Invalid: data in this block is “garbage”


Current Processor

![](https://raw.githubusercontent.com/zxc2012/image/main/20220510101653.png)

Response to Other Processors

![](https://raw.githubusercontent.com/zxc2012/image/main/20220510102030.png)

Problem: Writing to Shared is Expensive

- If block is in shared, need to check if other caches have data (so we can invalidate) if we want to write
- If block is in modified, don’t need to check other caches if we want to write.

### MESI

||Valid Bit| Dirty Bit| Shared Bit|
|-|-|-|-|
|Modified| 1 |1| 0|
|Exclusive| 1| 0 |0|
|Shared |1 |0 |1 |
|Invalid| 0 |X |X |

- Exclusive: up-to-date data, OK to write (change to modified)
    - no other cache has a copy
- Shared: up-to-date data, not allowed to write
    - other caches have a up-to-date copy

Current Processor

![20220510102848](https://raw.githubusercontent.com/zxc2012/image/main/20220510102848.png)

Response to Other Processors

![20220510102848](https://raw.githubusercontent.com/zxc2012/image/main/20220510102939.png)

Problem: Expensive to Share Modified

In MSI and MESI, if we want to share block in modified, Modified data has to write back to memory

### MOESI

||Valid Bit| Dirty Bit| Shared Bit|
|-|-|-|-|
|Modified| 1 |1| 0|
|Owned |1| 1 |1|
|Exclusive| 1| 0 |0|
|Shared |1 |0 |1 |
|Invalid| 0 |X |X |

- Owner: up-to-date data, read-only (like shared, you can write if you invalidate shared copies first and your state changes to **modified**)
    - Owner supplies data on probe read instead of going to memory
- Shared: up-to-date data, not allowed to write
    - copy in memory ~~is~~ may be up-to-date

Current Processor

![20220510102848](https://raw.githubusercontent.com/zxc2012/image/main/20220510104017.png)

Response to Other Processors

![20220510102848](https://raw.githubusercontent.com/zxc2012/image/main/20220510104121.png)

### False Sharing vs. Real Sharing

False Sharing: Block ping-pongs between two caches even though processors are accessing disjoint variables

![20220510102848](https://raw.githubusercontent.com/zxc2012/image/main/20220510105104.png)

Real Sharing

![20220510102848](https://raw.githubusercontent.com/zxc2012/image/main/20220510105252.png)

Assume	x1	and	x2	in	same	cache	line. P1	and	P2	both	read	x1	and	x2	previously.

![20220510102848](https://raw.githubusercontent.com/zxc2012/image/main/20220510173055.png)

### Directory Cache System

Cache controllers do not observe all activity, but interact only with directory

![20220510102848](https://raw.githubusercontent.com/zxc2012/image/main/20220512155437.png)

For each cache line,there are 4	possible states(based on MSI):	
- C-invalid(=Nothing)
- C-shared(=Sh)
- C-modified(=Ex)
- C-transient(=Pending):for example, the site has just issued a	protocol request,but has not received the corresponding protocol reply).

For	each memory	line,there are	4 possible directory states:
- R(dir):The memory	line is	read-only by the sites specified in dir(dir is	a set of sites).If	dir	is	empty,the	memory line is not cached	by	any	site.
- W(id):The	memory line is	exclusively	cached	at	site id,and	has	been modified at that site.
- TR(dir)
- TW(id)

Directory: one bit for each  processor that is sharing or for the  single processor that has the modified  line

![20220512155625](https://raw.githubusercontent.com/zxc2012/image/main/20220512155625.png)

Read miss,to uncached or shared	line

![20220512155625](https://raw.githubusercontent.com/zxc2012/image/main/20220512160731.png)

Write miss,to read shared line

![20220512155625](https://raw.githubusercontent.com/zxc2012/image/main/20220512160920.png)

## Sequential Consistency

Sequential	Consistency: A system is sequentially consistent if	the	result	of	any	execution is the same as if	the	operations of all the processors were executed in	some sequential	order

- Only a few commercial ISAs require SC(Neither RISCV nor X86)
- Weaker memory	models -> fewer	guarantees

Producer-Consumer: Consumer lw xdata has to be done after lw xflag

![20220512155625](https://raw.githubusercontent.com/zxc2012/image/main/20220512202509.png)

Solutions

1. Total store ordering (TSO)

    Processor P can read B before its write to A is seen by all processors


    ![20220512155625](https://raw.githubusercontent.com/zxc2012/image/main/20220512202931.png)

    Possible Outcomes(Blue could be done before red)

    |P1.x2| P2.x2| SC |TSO|
    |-|-|-|-|
    |0 |0 |N| Y|
    |0 |1| Y| Y|
    |1 |0 |Y |Y|
    |1 |1| Y| Y|

2. Fences

    ![20220512155625](https://raw.githubusercontent.com/zxc2012/image/main/20220512203822.png)