# CS61C Lecture4 --Cache

## Basic

![](https://raw.githubusercontent.com/zxc2012/image/main/20220414195448.png)

### Principle of Locality

- Temporal Locality (locality in time)

    If a memory location is referenced then it will tend to be referenced again soon

- Spatial Locality (locality in space)

    If a memory location is referenced, the locations with nearby addresses will tend to be referenced soon

### Caching Terminology

- **Cache hit**

    Cache holds a valid copy of the block, so return the desired data

- **Cache miss**

    Cache does not have desired block, so fetch from memory and put in empty (invalid) slot

Average Memory Access Time(AMAT) = Hit time + Miss rate × 
Miss penalty

### Cache block replacement policy

- Random Replacement

- Least Recently Used (LRU)

    Replace block we used least recently first in the hopes we will use it again later than all other blocks

### Caching Read & Write

we assume the use of separate instruction and data
caches (Icache and Dcache)
- Read from both
- Write only to Dcache (assume no self-modifying code)

Write Hits

- **Write-Through** Policy: Always write data to
cache and to memory (through cache)

- **Write-Back** Policy: Write data only to cache,
then update memory when block is removed

    Dirty bit: Extra bit per cache row that is set if block was written to (is “dirty”) and needs to be written back

Write Miss

- **Write Allocate** policy: when we bring the block
into the cache after a write miss

    Write allocate almost always paired with write-back(Memory is always up-to-date)

- **No Write Allocate** policy: only change main
memory after a write miss
    
    No write allocate typically paired with write-through(Cache is always up-to-date)

## Processor Address Fields

a cache of fixed size (C), Memory is (A) byte-addressed

- Offset: denotes block size: (# = K) Bytes
- Index:  Can’t fit all blocks at once, multiple blocks in memory must map to the same “set” in cache 

    (# = $log_2{(C/K/N)}$)

    - Fully associative (1 set): 0 Index bits!
    - Direct-mapped (N = 1): max Index bits
    - N-way set-associative: somewhere in-between
    
- Tag: f identifying which memory block is currently in each
cache slot (T = A – I – O)

<table>
<tr><th>type</th><th colspan="3">Fields</th></tr>
<tr><td>Fully Associative</td><td colspan ="2">Tag</td><td>Offset</td></tr>
<tr><td>Direct-mapped</td><td>Tag</td><td>Index</td><td>Offset</td></tr>
<tr><td>N-way set-associative</td><td>Tag</td><td>Index</td><td>Offset</td></tr>
</table>

![20220414205040](https://raw.githubusercontent.com/zxc2012/image/main/20220414212245.png)

### Fully Associative Cache

- Total bits

    In a slot:

    - Tag field of address as identifier (Tag bits)
    - Valid bit (1 bit): Whether cache slot was filled in
    - Dirty bit (1 bit if write-back)
    - Any necessary replacement management bits (“LRU bits”)

    Total bits in cache = $(C/K) \times (8 \times 2^{O} + Tag + 1 + 1 + ?)$ bits

- To check a fully associative cache

    1. Look at ALL cache slots in sequence
    2. If Valid bit is 0, then ignore
    3. If Valid bit is 1 and Tag matches, then return that data

- Example

    Offset – 2 bits, Tag – 4 bits

    ![20220414205040](https://raw.githubusercontent.com/zxc2012/image/main/20220414205356.png)

    ![20220414205845](https://raw.githubusercontent.com/zxc2012/image/main/20220414205845.png)

    Same requests, but reordered

    ![20220414205845](https://raw.githubusercontent.com/zxc2012/image/main/20220414205939.png)

    ![20220414205845](https://raw.githubusercontent.com/zxc2012/image/main/20220414210035.png)

    Original sequence, but double block size

    ![20220414205845](https://raw.githubusercontent.com/zxc2012/image/main/20220414210248.png)

    ![20220414205845](https://raw.githubusercontent.com/zxc2012/image/main/20220414210332.png)

### Direct-Mapped

- Total bits

    Total bits in cache = $(C/K) \times (8 \times 2^{O} + Tag + 1 + 1 + ?)$ bits

- Example

    ![20220414211441](https://raw.githubusercontent.com/zxc2012/image/main/20220414211441.png)

    ![20220414211441](https://raw.githubusercontent.com/zxc2012/image/main/20220414212020.png)

    ![20220414212112](https://raw.githubusercontent.com/zxc2012/image/main/20220414212112.png)

### N-way set-associative

Divide Cache into sets, each of which consists of N slots

- Memory block maps to a set determined by Index field and is placed in any of the N slots of that set
- Replacement policy applies to every set

Total bits = $2^I \times N \times (8 \times 2^{O} + Tag + 1 + 1 + ?)$ bits

![20220414212112](https://raw.githubusercontent.com/zxc2012/image/main/20220414212912.png)

![20220414212112](https://raw.githubusercontent.com/zxc2012/image/main/20220421204734.png)

Example

![20220414212112](https://raw.githubusercontent.com/zxc2012/image/main/20220414213103.png)

Compulsory Miss: 0(first),4,8,20,16

Capacity Miss: 0(second) (after its last access we have unique block accesses to 0001,0010,0101,0100, but we only have space for 4−1=3 more unique accesses)

![20220414213153](https://raw.githubusercontent.com/zxc2012/image/main/20220414213153.png)

![20220414213239](https://raw.githubusercontent.com/zxc2012/image/main/20220414213239.png)

## Cache Questions

### AMAT

3 parameters: Hit time, miss rate, miss penalty

- Hit Time
    - Cache size decreases → hit time decreases
    - associativity increases → hit time increases
- Miss Rate
    - Larger blocks, larger caches, more associativity can hold more data → miss rate decreases
    - 3Cs
- Miss penalty
    - Multilevel caches
    - Smaller block size → lower MP

3Cs(Sources of Cache Misses):

- **Compulsory**: First access to block impossible to avoid
    - Increase block size (increases MP; too large blocks could increase MR because the number of blocks that can be held in the same size cache is smaller)
- **Capacity**: Cache cannot contain all blocks accessed by the program
    - Increase cache size (may increase HT)
- **Conflict**: Multiple memory locations mapped to the same cache location
    - Increase associativity (to fully associative) (may increase HT)

Capacity or Conflict Miss

after the last access unique block accesses vs Fully Associative Space -1 

### Multilevel Caches

Design Considerations

- L1 cache focuses on *low hit time* (fast access)
    - e.g. smaller cache
- L2 L3 focus on low *miss rate*
    - e.g. larger cache with larger block sizes

Local vs. Global Miss Rates

- Local miss rate: Fraction of references to one level of a cache that miss
    - e.g.  L2 local MR = L2 misses/L1 misses
- Global miss rate: Fraction of all references that miss in all levels of a multilevel cache
    - Global MR is the product of all local MRs

