"use strict";(self.webpackChunkChance=self.webpackChunkChance||[]).push([[6081],{2309:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>_,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>r,toc:()=>d});var i=t(7462),s=(t(7294),t(3905));t(1839);const a={},o="\u57fa\u4e8eCNN-LSTM\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u5173\u7cfb\u62bd\u53d6\u8054\u5408\u5b66\u4e60",r={unversionedId:"AI/NLP",id:"AI/NLP",title:"\u57fa\u4e8eCNN-LSTM\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u5173\u7cfb\u62bd\u53d6\u8054\u5408\u5b66\u4e60",description:"Word2vec",source:"@site/docs/AI/NLP.md",sourceDirName:"AI",slug:"/AI/NLP",permalink:"/docs/AI/NLP",draft:!1,editUrl:"https://github.com/zxc2012/zxc2012.github.io/tree/master/docs/AI/NLP.md",tags:[],version:"current",frontMatter:{},sidebar:"AI",next:{title:"GPU",permalink:"/docs/AI/config"}},_={},d=[{value:"Word2vec",id:"word2vec",level:2},{value:"Gensim\u8bad\u7ec3Word2vec\u6b65\u9aa4",id:"gensim\u8bad\u7ec3word2vec\u6b65\u9aa4",level:3},{value:"Tagging scheme",id:"tagging-scheme",level:2},{value:"Evaluate",id:"evaluate",level:2}],l={toc:d};function c(e){let{components:n,...t}=e;return(0,s.kt)("wrapper",(0,i.Z)({},l,t,{components:n,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"\u57fa\u4e8ecnn-lstm\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u5173\u7cfb\u62bd\u53d6\u8054\u5408\u5b66\u4e60"},"\u57fa\u4e8eCNN-LSTM\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u5173\u7cfb\u62bd\u53d6\u8054\u5408\u5b66\u4e60"),(0,s.kt)("h2",{id:"word2vec"},"Word2vec"),(0,s.kt)("h3",{id:"gensim\u8bad\u7ec3word2vec\u6b65\u9aa4"},"Gensim\u8bad\u7ec3Word2vec\u6b65\u9aa4"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"1 \u5c06\u8bed\u6599\u5e93\u9884\u5904\u7406\uff1a\u4e00\u884c\u4e00\u4e2a\u6587\u6863\u6216\u53e5\u5b50\uff0c\u5c06\u6587\u6863\u6216\u53e5\u5b50\u5206\u8bcd\uff08\u4ee5\u7a7a\u683c\u5206\u5272\uff0c\u82f1\u6587\u53ef\u4ee5\u4e0d\u7528\u5206\u8bcd\uff0c\u82f1\u6587\u5355\u8bcd\u4e4b\u95f4\u5df2\u7ecf\u7531\u7a7a\u683c\u5206\u5272\uff0c\u4e2d\u6587\u9884\u6599\u9700\u8981\u4f7f\u7528\u5206\u8bcd\u5de5\u5177\u8fdb\u884c\u5206\u8bcd\uff0c\n\u5e38\u89c1\u7684\u5206\u8bcd\u5de5\u5177\u6709StandNLP\u3001ICTCLAS\u3001Ansj\u3001FudanNLP\u3001HanLP\u3001\u7ed3\u5df4\u5206\u8bcd\u7b49\uff09\uff1b")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"2 \u5c06\u539f\u59cb\u7684\u8bad\u7ec3\u8bed\u6599\u8f6c\u5316\u6210\u4e00\u4e2asentence\u7684\u8fed\u4ee3\u5668\uff0c\u6bcf\u4e00\u6b21\u8fed\u4ee3\u8fd4\u56de\u7684sentence\u662f\u4e00\u4e2aword\uff08utf-8\u683c\u5f0f\uff09\u7684\u5217\u8868\u3002\u53ef\u4ee5\u4f7f\u7528Gensim\u4e2dword2vec.py\u4e2d\u7684LineSentence()\u65b9\u6cd5\u5b9e\u73b0\uff1b")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"3 \u5c06\u4e0a\u9762\u5904\u7406\u7684\u7ed3\u679c\u8f93\u5165Gensim\u5185\u5efa\u7684word2vec\u5bf9\u8c61\u8fdb\u884c\u8bad\u7ec3\u5373\u53ef\uff1a"))),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-py"},"import os\nimport json\nfrom gensim.models.word2vec import LineSentence, Word2Vec\n#\u5c06json\u8f6c\u6362\u4e3a\u539f\u6587,\u4e00\u884c\u4e00\u53e5\ndef func(fin, fout):\n    for line in fin:\n        line = line.strip()\n        if not line:\n            continue\n        sentence = json.loads(line)\n        sentence = sentence[\"sentText\"].strip().strip('\"').lower()\n        fout.write(sentence + '\\n')\n        \ndef make_corpus():\n    with open('data/NYT_CoType/corpus.txt', 'wt', encoding='utf-8') as fout:\n        with open('data/NYT_CoType/train.json', 'rt', encoding='utf-8') as fin:\n            func(fin, fout)\n        with open('data/NYT_CoType/test.json', 'rt', encoding='utf-8') as fin:\n            func(fin, fout)\nif __name__ == \"__main__\":\n    if not os.path.exists('data/NYT_CoType/corpus.txt'):\n        make_corpus()\n\n    sentences = LineSentence('data/NYT_CoType/corpus.txt')\n    '''\n    (1)size\uff1a\u662f\u6307\u8bcd\u5411\u91cf\u7684\u7ef4\u5ea6\uff0c\u9ed8\u8ba4\u4e3a100\u3002\u8fd9\u4e2a\u7ef4\u5ea6\u7684\u53d6\u503c\u4e00\u822c\u4e0e\u6211\u4eec\u7684\u8bed\u6599\u7684\u5927\u5c0f\u76f8\u5173\n    (2)workers\uff1a\u7528\u4e8e\u63a7\u5236\u8bad\u7ec3\u7684\u5e76\u884c\u6570\u3002\n    (3)sg:\u8bad\u7ec3\u6a21\u578b 0\u8868\u793aCBOW,1\u8868\u793askip-gram\n    (4)iter: \u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5\u4e2d\u8fed\u4ee3\u7684\u6700\u5927\u6b21\u6570\uff0c\u9ed8\u8ba4\u662f5\u3002\u5bf9\u4e8e\u5927\u8bed\u6599\uff0c\u53ef\u4ee5\u589e\u5927\u8fd9\u4e2a\u503c\u3002\n    (5)negative\uff1a\u5373\u4f7f\u7528Negative Sampling\u65f6\u8d1f\u91c7\u6837\u7684\u4e2a\u6570\uff0c\u9ed8\u8ba4\u662f5\u3002\u63a8\u8350\u5728[3,10]\u4e4b\u95f4\n    '''\n    model = Word2Vec(sentences, sg=1, size=300, workers=4, iter=8, negative=8)\n    word_vectors = model.wv\n    word_vectors =word_vectors\n    word_vectors.save('data/NYT_CoType/word2vec')\n    word_vectors.save_word2vec_format('data/NYT_CoType/word2vec.txt', fvocab='data/NYT_CoType/vocab.txt')\n")),(0,s.kt)("h2",{id:"tagging-scheme"},"Tagging scheme"),(0,s.kt)("p",null,"\u6839\u636e\u4e2d\u79d1\u9662\u8bba\u6587\u4e2d\u7684\u6807\u6ce8\uff0c\u8fd9\u91cc\u4e3e\u4f8b\u5982\u4e0b:\n",(0,s.kt)("img",{parentName:"p",src:"https://img-blog.csdnimg.cn/20200521212641784.png",alt:"dcas"})),(0,s.kt)("p",null,"\u9884\u5904\u7406\u8fc7\u7a0b\u4e3b\u8981\u6ce8\u610f\u51e0\u4e2a\u8981\u70b9:"),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"1 \u8f6c\u6362\u5927\u5c0f\u5199")),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"2 \u957f\u5ea6\u4e0d\u591f\u8981padding")),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"3 \u5c06\u5e26\u58f0\u8c03\u97f3\u8282(\u5982\u4e00\u4e9b\u6cd5\u8bed\u5355\u8bcd)\u53d8\u5f62\uff0c\u8fd9\u91cc\u91c7\u7528\u5148\u8f6c\u6362\u4e3aunicode\u518d\u53d8\u56de\u53bb\u7684\u529e\u6cd5"),(0,s.kt)("pre",{parentName:"blockquote"},(0,s.kt)("code",{parentName:"pre",className:"language-py"},'def make_tag_set(tag_set, relation_label):\n    \'\'\'\n    make_tag_set(tag_set, relation_mention["label"])\n    \'\'\'\n    if relation_label == "None":\n        return\n    for pos in "BIES":\n       for role in "12":\n           tag_set.add("-".join([pos, relation_label, role]))#pos-relation_label-role\n'))),(0,s.kt)("p",null,"def update_tag_seq(em_text, sentence_text, relation_label, role, tag_set, tags_idx):\n'''\nres1 = update_tag_seq(em1_text, sentence_text, relation_mention",'["label"]',", 1, tag_set, tags_idx)"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'B-begin\uff0cI-inside\uff0cO-outside\uff0cE-end\uff0cS-single\n\n\u4ee5\u4e0b\u5747\u4ee5\u8bcd\u4e3a\u5355\u4f4d\n\'\'\'\noverlap = False\nstart = search(em_text, sentence_text)#\u9996\u8bcd\u7684\u8bcdindex\ntag = "-".join(["S", relation_label, str(role)])\nif len(em_text) == 1:\n    if tags_idx[start] != tag_set["O"]:\n        overlap = True\n    tags_idx[start] = tag_set[tag]\nelse:\n    tag = "B" + tag[1:]\n    if tags_idx[start] != tag_set["O"]:\n        overlap = True\n    tags_idx[start] = tag_set[tag]\n    tag = "E" + tag[1:]\n    end = start + len(em_text) - 1\n    if tags_idx[end] != tag_set["O"]:\n        overlap = True\n    tags_idx[end] = tag_set[tag]\n    tag = "I" + tag[1:]\n    for index in range(start + 1, end):\n        if tags_idx[index] != tag_set["O"]:\n            overlap = True\n        tags_idx[index] = tag_set[tag]\nreturn overlap\n')),(0,s.kt)("p",null,"def prepare_data_set(fin, charset, vocab, relation_labels, entity_labels, tag_set, dataset, fout):\n'''\nres=prepare_data_set(fin, charset, vocab, relation_labels, entity_labels, tag_set, train, fout)"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'fin:data/NYT_CoType/train.json\n\'\'\'\nnum_overlap = 0\nfor line in fin:\n    overlap = False\n    line = line.strip()#\u79fb\u9664\u5b57\u7b26\u4e32\u5934\u5c3e\u6307\u5b9a\u7684\u5b57\u7b26\uff08\u9ed8\u8ba4\u4e3a\u7a7a\u683c\u6216\u6362\u884c\u7b26\uff09\u6216\u5b57\u7b26\u5e8f\u5217\u3002\n    if not line:\n        continue\n    sentence = json.loads(line)\n    for entity_mention in sentence["entityMentions"]:\n        entity_labels.add(entity_mention["label"])\n\n    for relation_mention in sentence["relationMentions"]:\n        relation_labels.add(relation_mention["label"])\n        make_tag_set(tag_set, relation_mention["label"])\n\n    sentence_text = sentence["sentText"].strip().strip(\'"\')\n    sentence_text = unicodedata.normalize(\'NFKD\', sentence_text).encode(\'ascii\',\'ignore\').decode().split()#\u539f\u53e5\u7684\u4e00\u4e2a\u4e2a\u8bcd\n    #split():\u7a7a\u767d\u7b26\u5206\u9694,\u4e0d\u5305\u542b\u5e8f\u5217\u5f00\u5934\u6216\u672b\u5c3e\u7684\u7a7a\u767d\u7b26\u3002\n    length_sent = len(sentence_text)\n    if length_sent > MAX_SENT_LENGTH:\n        continue\n    lower_sentence_text = [token.lower() for token in sentence_text]\n    sentence_idx = prepare_sequence(lower_sentence_text, vocab)#\u8fd4\u56devocab\u7f16\u53f7\u6784\u6210\u7684list\n\n    tokens_idx = []#\u5b57\u6bcd\u7f16\u53f7\n    for token in sentence_text:\n        if len(token) <= MAX_TOKEN_LENGTH:\n            tokens_idx.append(prepare_sequence(token, charset) + [charset["<pad>"]]*(MAX_TOKEN_LENGTH-len(token)))#\u8865\u5168\n        else:\n            tokens_idx.append(prepare_sequence(token[0:13] + token[-7:], charset))#\u4e24\u7aef\u5f00\u82b1\n\n    tags_idx = [tag_set["O"]] * length_sent #tag2id\n    \n    for relation_mention in sentence["relationMentions"]:\n      if relation_mention["label"] == "None":\n           continue\n       em1_text = unicodedata.normalize(\'NFKD\', relation_mention["em1Text"]).encode(\'ascii\',\'ignore\').decode().split()\n       res1 = update_tag_seq(em1_text, sentence_text, relation_mention["label"], 1, tag_set, tags_idx)\n       em2_text = unicodedata.normalize(\'NFKD\', relation_mention["em2Text"]).encode(\'ascii\',\'ignore\').decode().split()\n       res2 = update_tag_seq(em2_text, sentence_text, relation_mention["label"], 2, tag_set, tags_idx)\n       if res1 or res2:\n           num_overlap += 1\n           overlap = True\n    dataset.append((sentence_idx, tokens_idx, tags_idx))\n    # if overlap:\n    #     fout.write(line+"\\n")\n    newsent = dict()\n    newsent[\'tokens\'] = lower_sentence_text\n    newsent[\'tags\'] = tags_idx\n    fout.write(json.dumps(newsent)+\'\\n\')\nreturn num_overlap\n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'## End2End Model\n![\u5728\u8fd9\u91cc\u63d2\u5165\u56fe\u7247\u63cf\u8ff0](https://img-blog.csdnimg.cn/20200521213114432.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5MzgwMjMw,size_16,color_FFFFFF,t_70)\n### CNN Encoder\n\u5176\u4e2d\uff0c\u7b2c\u4e00\u5c42\u5377\u79ef\u5c42\u53ef\u8868\u793a\u4e3a\n![\u5728\u8fd9\u91cc\u63d2\u5165\u56fe\u7247\u63cf\u8ff0](https://img-blog.csdnimg.cn/2020052121322775.png)\n\u5377\u79ef\u6838\u4e3a3\uff0c\u518d\u7ecf\u8fc7\u4e24\u5c42\u5377\u79ef\n\n### LSTM Decoder\n![\u5728\u8fd9\u91cc\u63d2\u5165\u56fe\u7247\u63cf\u8ff0](https://img-blog.csdnimg.cn/20200521213511827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5MzgwMjMw,size_16,color_FFFFFF,t_70)\n```py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom conv_net import ConvNet\nimport numpy as np\nimport torch.autograd as autograd\nfrom torch.autograd import Variable\n\n\nclass CharEncoder(nn.Module):\n\n    """\n    Input: (batch_size, seq_len)\n    Output: (batch_size, conv_size)\n    """\n    def __init__(self, char_num, embedding_size, channels, kernel_size, padding_idx, dropout, emb_dropout):\n        super(CharEncoder, self).__init__()\n        self.embed = nn.Embedding(char_num, embedding_size, padding_idx=padding_idx)\n        self.drop = nn.Dropout(emb_dropout)\n        self.conv_net = ConvNet(channels, kernel_size, dropout=dropout)\n        self.init_weights()\n\n    def forward(self, inputs):\n        seq_len = inputs.size(1)\n\n        # (batch_size, seq_len) -> (batch_size, seq_len, embedding_size) -> (batch_size, embedding_size, seq_len)\n        embeddings = self.drop(self.embed(inputs)).transpose(1, 2).contiguous()\n\n        # (batch_size, embedding_size, seq_len) -> (batch_size, conv_size, seq_len)\n        #  -> (batch_size, conv_size, 1) -> (batch_size, conv_size)\n        return F.max_pool1d(self.conv_net(embeddings), seq_len).squeeze()\n\n    def init_weights(self):\n        nn.init.kaiming_uniform_(self.embed.weight.data, mode=\'fan_in\', nonlinearity=\'relu\')\n\n\nclass WordEncoder(nn.Module):\n    """\n    Input: (batch_size, seq_len), (batch_size, seq_len, char_features)\n    """\n    def __init__(self, weight, channels, kernel_size, dropout, emb_dropout):\n        super(WordEncoder, self).__init__()\n        self.embed = nn.Embedding.from_pretrained(weight, freeze=False)\n        self.drop = nn.Dropout(emb_dropout)\n        self.conv_net = ConvNet(channels, kernel_size, dropout, dilated=True, residual=False)\n\n    def forward(self, word_input, char_input):\n        # (batch_size, seq_len) -> (batch_size, seq_len, embedding_size)\n        #  -> (batch_size, seq_len, embedding_size + char_features)\n        #  -> (batch_size, embedding_size + char_features, seq_len)\n        embeddings = torch.cat((self.embed(word_input), char_input), 2).transpose(1, 2).contiguous()\n\n        #print("embeddings:----------",embeddings.size())\n\n        # (batch_size, embedding_size + char_features, seq_len) -> (batch_size, conv_size, seq_len)\n        conv_out = self.conv_net(self.drop(embeddings))\n\n        # (batch_size, conv_size, seq_len) -> (batch_size, conv_size + embedding_size + char_features, seq_len)\n        #  -> (batch_size, seq_len, conv_size + embedding_size + char_features)\n        return torch.cat((embeddings, conv_out), 1).transpose(1, 2).contiguous()\n\n#self.char_conv_size+self.word_embedding_size+self.word_conv_size, num_tag\n\nclass Decoder(nn.Module):\n    def __init__(self,input_size,hidden_dim,output_size,NUM_LAYERS):\n        super(Decoder, self).__init__()\n        self.input_size=input_size\n        self.hidden_dim = hidden_dim\n        self.output_size=output_size\n\n        self.lstm = nn.LSTM(input_size, hidden_dim, num_layers = NUM_LAYERS,bidirectional=True)#update on 5.21\n        self.hidden2label = nn.Linear(2*self.hidden_dim, output_size)#update on 5.21\n        self.init_weight()\n\n    def forward(self, inputs):\n        self.lstm.flatten_parameters()\n        lstm_out, self.hidden = self.lstm(inputs,None)\n        y = self.hidden2label(lstm_out)\n        return y\n\n    def init_weight(self):\n        nn.init.kaiming_uniform_(self.hidden2label.weight.data, mode=\'fan_in\', nonlinearity=\'relu\')\n\n    def init_hidden(self, batch_size):\n        return (autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)),\n                autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)))\n\nclass Model(nn.Module):\n    def __init__(self, charset_size, char_embedding_size, char_channels, char_padding_idx, char_kernel_size,\n                 weight, word_embedding_size, word_channels, word_kernel_size, num_tag, dropout, emb_dropout):\n        super(Model, self).__init__()\n        self.char_encoder = CharEncoder(charset_size, char_embedding_size, char_channels, char_kernel_size,\n                                        char_padding_idx, dropout=dropout, emb_dropout=emb_dropout)\n        self.word_encoder = WordEncoder(weight, word_channels, word_kernel_size,\n                                        dropout=dropout, emb_dropout=emb_dropout)\n        self.drop = nn.Dropout(dropout)\n        self.char_conv_size = char_channels[-1]\n        self.word_embedding_size = word_embedding_size\n        self.word_conv_size = word_channels[-1]\n        #self.decoder = nn.Linear(self.char_conv_size+self.word_embedding_size+self.word_conv_size, num_tag)\n        self.decoder = Decoder(self.char_conv_size+self.word_embedding_size+self.word_conv_size,\n                               self.char_conv_size + self.word_embedding_size + self.word_conv_size,\n                               num_tag,NUM_LAYERS=1)\n        self.init_weights()\n\n    def forward(self, word_input, char_input):\n        batch_size = word_input.size(0)\n        seq_len = word_input.size(1)\n        char_output = self.char_encoder(char_input.view(-1, char_input.size(2))).view(batch_size, seq_len, -1)\n        word_output = self.word_encoder(word_input, char_output)\n        y = self.decoder(word_output)\n\n        return F.log_softmax(y, dim=2)\n\n    def init_weights(self):\n        pass\n        #self.decoder.bias.data.fill_(0)\n        #nn.init.kaiming_uniform_(self.decoder.weight.data, mode=\'fan_in\', nonlinearity=\'relu\')\n\nword_embeddings = torch.tensor(np.load("data/NYT_CoType/word2vec.vectors.npy"))\nprint(word_embeddings.shape)\ndropout=(0.5,)\nemb_dropout=0.25\n\nif __name__ == "__main__":\n    model=Model(charset_size=96, char_embedding_size=50, char_channels=[50, 50, 50, 50],\n              char_padding_idx=94, char_kernel_size=3, weight=word_embeddings,\n              word_embedding_size=300, word_channels=[350, 300, 300, 300],\n              word_kernel_size=3, num_tag=193, dropout=0.5,\n              emb_dropout=0.25)\n    print(model)\n')),(0,s.kt)("h2",{id:"evaluate"},"Evaluate"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-py"},'def measure(output, targets, lengths):\n    assert output.size(0) == targets.size(0) and targets.size(0) == lengths.size(0)\n    tp = 0\n    tp_fp = 0\n    tp_fn = 0\n    batch_size = output.size(0)\n    output = torch.argmax(output, dim=-1)#\u5f97\u5230\u6700\u5927\u503c\u7684\u5e8f\u53f7\u7d22\u5f15,dim:\u8981\u6d88\u53bb\u7684\u7ef4\u5ea6\n    for i in range(batch_size):\n        length = lengths[i]\n        out = output[i][:length].tolist()\n        target = targets[i][:length].tolist()\n        out_triplets = get_triplets(out)\n        tp_fp += len(out_triplets)\n        target_triplets = get_triplets(target)\n        tp_fn += len(target_triplets)\n        for target_triplet in target_triplets:\n            for out_triplet in out_triplets:\n                if out_triplet == target_triplet:\n                    tp += 1\n    return tp, tp_fp, tp_fn\n    \n def evaluate(data_groups):\n    model.eval()\n    total_loss = 0\n    count = 0\n    TP = 0\n    TP_FP = 0\n    TP_FN = 0\n    with torch.no_grad():#\u4e0d\u8ddf\u8e2a\u8ba1\u7b97\u68af\u5ea6\n        for batch_indices in GroupBatchRandomSampler(data_groups, args.batch_size, drop_last=False):\n            sentences, tokens, targets, lengths = get_batch(batch_indices, train_data)\n            output = model(sentences, tokens)\n            tp, tp_fp, tp_fn = measure(output, targets, lengths)\n            TP += tp\n            TP_FP += tp_fp\n            TP_FN += tp_fn\n            output = pack_padded_sequence(output, lengths, batch_first=True).data\n            targets = pack_padded_sequence(targets, lengths, batch_first=True).data\n            loss = criterion(output, targets)\n            total_loss += loss.item()\n            count += len(targets)\n    return total_loss / count, TP/TP_FP, TP/TP_FN, 2*TP/(TP_FP+TP_FN)\n    \ndef get_triplets(tags):\n    temp = {}\n    triplets = []\n    for idx, tag in enumerate(tags):\n        if tag == tag_set["O"]:\n            continue\n        pos, relation_label, role = tag_set[tag].split("-")\n        if pos == "B" or pos == "S":\n            if relation_label not in temp:\n                temp[relation_label] = [[], []]\n            temp[relation_label][int(role) - 1].append(idx)\n    for relation_label in temp:\n        role1, role2 = temp[relation_label]\n        if role1 and role2:\n            len1, len2 = len(role1), len(role2)\n            if len1 > len2:\n                for e2 in role2:\n                    idx = np.argmin([abs(e2 - e1) for e1 in role1])\n                    e1 = role1[idx]\n                    triplets.append((e1, relation_label, e2))\n                    del role1[idx]\n            else:\n                for e1 in role1:\n                    idx = np.argmin([abs(e2 - e1) for e2 in role2])\n                    e2 = role2[idx]\n                    triplets.append((e1, relation_label, e2))\n                    del role2[idx]\n    return triplets\n')))}c.isMDXComponent=!0}}]);